{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAlKTW4n5XAA",
        "outputId": "6490e3f0-819f-494d-d339-1a230f1e5200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m563.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, gensim\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 scipy-1.13.1\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install gensim numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "d5OAKy2klABu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm"
      ],
      "metadata": {
        "id": "pcm03apMl8P1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained word vectors\n",
        "print(\"Loading pre-trained word vectors...\")\n",
        "word_vectors = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHBeWzWcl-_7",
        "outputId": "8b8e0297-617f-4e46-bc86-c2a0ec397d8a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-trained word vectors...\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform vector arithmetic and find similar words\n",
        "def explore_word_relationships(word1, word2, word3):\n",
        "  try:\n",
        "# Get vectors for the input words\n",
        "    vec1 = word_vectors[word1]\n",
        "    vec2 = word_vectors[word2]\n",
        "    vec3 = word_vectors[word3]\n",
        "# Perform vector arithmetic: word1 - word2 + word3\n",
        "    result_vector = vec1 - vec2 + vec3\n",
        "# Find the most similar words to the resulting vector\n",
        "    similar_words = word_vectors.similar_by_vector(result_vector, topn=10)\n",
        "# Exclude input words from the results\n",
        "    input_words = {word1, word2, word3}\n",
        "    filtered_words = [(word, similarity) for word, similarity in similar_words if word not in input_words]\n",
        "    print(f\"\\nWord Relationship: {word1} - {word2} + {word3}\")\n",
        "    print(\"Most similar words to the result (excluding input words):\")\n",
        "    for word, similarity in filtered_words[:5]: # Show top 5 results\n",
        "      print(f\"{word}: {similarity:.4f}\")\n",
        "  except KeyError as e:\n",
        "    print(f\"Error: {e} not found in the vocabulary.\")"
      ],
      "metadata": {
        "id": "boNZTQQrmC2V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example word relationships to explore\n",
        "explore_word_relationships(\"king\", \"man\", \"woman\")\n",
        "explore_word_relationships(\"paris\", \"france\", \"germany\")\n",
        "explore_word_relationships(\"apple\", \"fruit\", \"carrot\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VMqmxkaoWef",
        "outputId": "b8050f64-88d1-4c5a-e58c-8ce3e50c4053"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Relationship: king - man + woman\n",
            "Most similar words to the result (excluding input words):\n",
            "queen: 0.7301\n",
            "monarch: 0.6455\n",
            "princess: 0.6156\n",
            "crown_prince: 0.5819\n",
            "prince: 0.5777\n",
            "\n",
            "Word Relationship: paris - france + germany\n",
            "Most similar words to the result (excluding input words):\n",
            "berlin: 0.4838\n",
            "german: 0.4695\n",
            "lindsay_lohan: 0.4536\n",
            "switzerland: 0.4468\n",
            "heidi: 0.4445\n",
            "\n",
            "Word Relationship: apple - fruit + carrot\n",
            "Most similar words to the result (excluding input words):\n",
            "carrots: 0.5700\n",
            "proverbial_carrot: 0.4578\n",
            "Carrot: 0.4159\n",
            "Twizzler: 0.4074\n",
            "peppermint_candy: 0.4074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to analyze the similarity between two words\n",
        "def analyze_similarity(word1, word2):\n",
        "  try:\n",
        "    similarity = word_vectors.similarity(word1, word2)\n",
        "    print(f\"\\nSimilarity between '{word1}' and '{word2}': {similarity:.4f}\")\n",
        "  except KeyError as e:\n",
        "    print(f\"Error: {e} not found in the vocabulary.\")"
      ],
      "metadata": {
        "id": "gFUfSWjAoaHU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example similarity analysis\n",
        "analyze_similarity(\"cat\", \"dog\")\n",
        "analyze_similarity(\"computer\", \"keyboard\")\n",
        "analyze_similarity(\"music\", \"art\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGfZ3u5RovMw",
        "outputId": "70e25f0b-2a2c-4867-bf42-581f17db7cac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Similarity between 'cat' and 'dog': 0.7609\n",
            "\n",
            "Similarity between 'computer' and 'keyboard': 0.3964\n",
            "\n",
            "Similarity between 'music' and 'art': 0.4010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find the most similar words to a given word\n",
        "def find_most_similar(word):\n",
        "  try:\n",
        "    similar_words = word_vectors.most_similar(word, topn=5)\n",
        "    print(f\"\\nMost similar words to '{word}':\")\n",
        "    for similar_word, similarity in similar_words:\n",
        "      print(f\"{similar_word}: {similarity:.4f}\")\n",
        "  except KeyError as e:\n",
        "    print(f\"Error: {e} not found in the vocabulary.\")"
      ],
      "metadata": {
        "id": "dsDg98IAo0Ec"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Find most similar words\n",
        "find_most_similar(\"happy\")\n",
        "find_most_similar(\"sad\")\n",
        "find_most_similar(\"technology\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5opVdR2o-Cw",
        "outputId": "a6516a85-cfef-48d5-df60-99cb2209d937"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Most similar words to 'happy':\n",
            "glad: 0.7409\n",
            "pleased: 0.6632\n",
            "ecstatic: 0.6627\n",
            "overjoyed: 0.6599\n",
            "thrilled: 0.6514\n",
            "\n",
            "Most similar words to 'sad':\n",
            "saddening: 0.7273\n",
            "Sad: 0.6611\n",
            "saddened: 0.6604\n",
            "heartbreaking: 0.6574\n",
            "disheartening: 0.6507\n",
            "\n",
            "Most similar words to 'technology':\n",
            "technologies: 0.8332\n",
            "innovations: 0.6231\n",
            "technological_innovations: 0.6102\n",
            "technol: 0.6047\n",
            "technological_advancement: 0.6036\n"
          ]
        }
      ]
    }
  ]
}